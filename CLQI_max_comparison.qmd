
This QMD will be a subset of `simple_case.qmd`, exploring the sensitivity between choosing different max values for the transformation in CLQI. We have four values to try, some of which vary between simulations and some being constant, depending on our data generating mechanism

1) Max = max(observed_data)
2) Max = max(theoretical_data)
3) Max = quantile(distribution, q = 99.9999)
4) Max = quantile(distribution, q = 99.999999999), an arbitrary amount of 9s, but super high

```{r}
#necessary libraries
library(tidyverse)
library(ggplot2)
library(quantreg)
library(missMethods)
library(MASS)
library(purrr)
library(tictoc)
```

Some important transformation functions that we will use for the CLQI algorithm

```{r}
#logit and expit functions for myself
logit <- function(prob) {
  value <- log(prob / (1 - prob))
  return(value)
}

expit <- function(x) {
  value <- 1 / (1 + exp(-x))
  return(value)
}

#now some other transformation functions
log_quant_transform <- function(value, min, max) {
  if (is.na(value)) return(NA)  # short-circuit if missing
  if (value <= min | value >= max) return(NA)
  return(log((value - min) / (max - value)))
}

inv_log_quant_transform <- function(value, min, max) {
  new_value <- (exp(value)*max + min) / (1+exp(value))
  return(new_value)
}
```

The Data Generating Mechanism: just one study with a very simple mechanism defined in section 3

```{r}
#theoretical distribution values we need for transformations (chatgpt makes this quick)
get_mixture_quantile <- function(p) {
  uniroot(
    function(q) 0.6 * pchisq(q, 5) + 0.4 * pchisq(q, 8) - p,
    c(0, 1000)
  )$root
}

# Compute each quantile and assign to unique objects
q_9999 <- get_mixture_quantile(0.9999)
q_999999 <- get_mixture_quantile(0.999999)
```


```{r}
data_generation <- function(sample_size, missing_prop, 
                            b_0 = logit(0.1), b_1 = log(1.1), b_2 = log(0.7)) {

  #generate my data
  B <- rbinom(sample_size, size = 1, prob = 0.4)
  X <- rchisq(sample_size, df = 5 + 3*B) #if B = 1, X ~ chisq(8)
  Y <- plogis(b_0 + b_1*X + b_2*B) #we have some effects
  Y_bin <- rbinom(sample_size, size = 1, prob = Y)
  
  
  my_data <- data.frame(
      confounder = B,
      biomarker = X,
      missing_biomarker = X, #just me not being the best at coding... this is right
      outcome = Y_bin
    )
  
  my_data <- delete_MCAR(my_data, missing_prop, "missing_biomarker") #make missing_prop percent of data missing MCAR
  
  #now we create the transformed variable... sapply is NOT working
  my_data$transformed_biomarker_1 <- NA
  my_data$transformed_biomarker_2 <- NA
  my_data$transformed_biomarker_3 <- NA
  my_data$transformed_biomarker_4 <- NA
  
  #this is for scenario 1
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker_1[i] <- NA} 
    else {
      my_data$transformed_biomarker_1[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = max(my_data$missing_biomarker, na.rm = TRUE))}
  }
  
  #this is for scenario 2
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker_2[i] <- NA} 
    else {
      my_data$transformed_biomarker_2[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = max(my_data$biomarker, na.rm = TRUE))}
  }
  
  #this is for scenario 3
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker_3[i] <- NA} 
    else {
      my_data$transformed_biomarker_3[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = q_9999)}
  }
  
  #this is for scenario 4
  for(i in 1:nrow(my_data)) {
    if(is.na(my_data$missing_biomarker[i])) {
      my_data$transformed_biomarker_4[i] <- NA} 
    else {
      my_data$transformed_biomarker_4[i] <- log_quant_transform(my_data$missing_biomarker[i], 
                                                              min = 0, max = q_999999)}
  }
  
  return(my_data)
}
```

# CLQI algorithm for a single data point as a function

```{r}
imputation_algorithm <- function(my_data, row_index, biomarker_var, unif_value) {

  #formula string stuff
  formula_str <- paste(biomarker_var, "~ outcome + confounder")
  formula_obj <- as.formula(formula_str)
  
  #then do the regression
  reg_coeff <- rq(formula_obj,
                  data = my_data,
                  tau = unif_value) #straight up u value
  
  b_intercept <- reg_coeff$coefficients[1]
  b_outcome <- reg_coeff$coefficients[2]
  b_confounder <- reg_coeff$coefficients[3]
  
  imputation_value_transformed <- b_intercept + (b_outcome * my_data[row_index,]$outcome) + (b_confounder * my_data[row_index,]$confounder)
  
  return(imputation_value_transformed)
}


impute_multiple_biomarkers <- function(data, biomarker_vars) {
  for (biomarker_var in biomarker_vars) { #for all the biomarker variables we have with different transformations
    for (row_index in 1:nrow(data)) { #we index by each row
      if (is.na(data[row_index, biomarker_var])) { #if we have a missing value, we perform the algorithm with the same u val
        data[row_index, biomarker_var] <- imputation_algorithm(
          my_data = data,
          row_index = row_index,
          biomarker_var = biomarker_var,
          unif_value = runif(1, min = 0, max = 0.99) 
        )
      }
    }
  }
  return(data)
}
```

## The following is a demonstration of CLQI

```{r}
#here are the data that we need
data_for_imp <- data_generation(sample_size = 1000, missing_prop = 0.3)

#here are the variables that we pre-defined
biomarkers <- c("transformed_biomarker_1", "transformed_biomarker_2", 
                "transformed_biomarker_3", "transformed_biomarker_4")

#apply the massive function
data_for_imp <- impute_multiple_biomarkers(data_for_imp, biomarkers)

#multiple mutations for different types of max values, a sensitivity analysis
#this is not clean, but i don't want to hear it
data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker_1 = sapply(transformed_biomarker_1, inv_log_quant_transform, 
                                                  min = 0, max = max(data_for_imp$missing_biomarker, na.rm = TRUE)))

data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker_2 = sapply(transformed_biomarker_2, inv_log_quant_transform, 
                                                  min = 0, max = max(data_for_imp$biomarker, na.rm = TRUE)))

data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker_3 = sapply(transformed_biomarker_3, inv_log_quant_transform, 
                                                  min = 0, max = q_9999))

data_for_imp <- data_for_imp |>
  mutate(untransformed_imputed_biomarker_4 = sapply(transformed_biomarker_4, inv_log_quant_transform, 
                                                  min = 0, max = q_999999))

#for a sanity check!
data_for_imp #check the transformed_biomarker variable, not the missing_biomarker variable!
```

Now we will show what these distributions look like:

```{r, eval=FALSE}
data_for_imp_new <- data_for_imp
data_for_imp_new$confounder <- factor(data_for_imp_new$confounder, levels = c(0, 1), labels = c("Confounder = 0", "Confounder = 1"))

#some data transformation
data_long <- data_for_imp_new |>
  dplyr::select(!biomarker) |>
  pivot_longer(
    cols = starts_with("untransformed_imputed_biomarker_"),
    names_to = "biomarker",
    values_to = "value"
  )

ggplot(data_long, aes(x = value, fill = confounder, color = confounder)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ biomarker, scales = "free") +  # Adjust scales as needed
  labs(
    title = "Imputed Biomarker Distributions by Confounder",
    x = "Biomarker",
    y = "Density"
  ) +
  scale_fill_manual(values = c("skyblue", "orange")) +
  scale_color_manual(values = c("blue", "red")) +
  stat_function(fun = dchisq, args = list(df = 5), aes(color = NULL),
                linetype = "dashed", size = 1, color = "black") +
  stat_function(fun = dchisq, args = list(df = 8), aes(color = NULL),
                linetype = "dotted", size = 1, color = "darkgreen")
```

########################################################

Now for simulations: we defined a couple of functions to make verything much easier

```{r}
#rubin's rule for standard error is complicated, so just keep it in a simple function
rubin_rule_SE <- function(values_MI, SE_MI) { #both inputs are vectors
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  total_variance <- variance_within_MI + variance_between_MI + (variance_between_MI / length(values_MI))
  
  return(sqrt(total_variance))
}
```

```{r}
coverage <- function(parameter, SE, t_star, true_val) {
  if(parameter - t_star*SE <= true_val & true_val <= parameter + t_star*SE) {
    return(1)
  } else{
    return(0)
  }
}
```

```{r}
power <- function(values_MI, SE_MI, num_MI) {
  #t stat calculation
  wald <- mean(values_MI) / rubin_rule_SE(values_MI, SE_MI)
  
  #df calculation
  variance_within_MI <- mean((SE_MI)^2)
  variance_between_MI <- sum((values_MI - mean(values_MI))^2) / (length(values_MI) - 1)
  my_frac <- variance_between_MI / (num_MI * variance_within_MI)
  df <- ((num_MI - 1) / (1 + my_frac)^2) 
  
  #our p-value
  p_value <- 2 * (1 - pt(abs(wald), df))
  
  #return 1 if we reject H0 (from DGM, we know H1 to be true)
  return(ifelse(p_value < 0.05, 1, 0))
}
```

### *A FUNCTION FOR CLQI*

```{r}
CLQI <- function(my_data, num_MI_iter) {
  
  values_CLQI_1 <- c()
  SE_CLQI_1 <- c()
  values_CLQI_2 <- c()
  SE_CLQI_2 <- c()
  values_CLQI_3 <- c()
  SE_CLQI_3 <- c()
  values_CLQI_4 <- c()
  SE_CLQI_4 <- c()
  
  for(imp in 1:num_MI_iter) {
    my_data_iteration <- my_data #resets any imputation that happened
    
    biomarkers <- c("transformed_biomarker_1", "transformed_biomarker_2", 
                "transformed_biomarker_3", "transformed_biomarker_4")
    
    #applies the CLQI function to all the biomarkers we have
    my_data_iteration <- impute_multiple_biomarkers(my_data_iteration, biomarkers)
    
    #after the CLQI algorithm, untransform all our values
    
    my_data_iteration <- my_data_iteration |>
      mutate(untransformed_imputed_biomarker_1 = sapply(transformed_biomarker_1, inv_log_quant_transform, 
                                                        min = 0, max = max(my_data_iteration$missing_biomarker, na.rm = TRUE))) |>
      mutate(untransformed_imputed_biomarker_2 = sapply(transformed_biomarker_2, inv_log_quant_transform, 
                                                        min = 0, max = max(my_data_iteration$biomarker, na.rm = TRUE))) |>
      mutate(untransformed_imputed_biomarker_3 = sapply(transformed_biomarker_3, inv_log_quant_transform, 
                                                        min = 0, max = q_9999)) |>
      mutate(untransformed_imputed_biomarker_4 = sapply(transformed_biomarker_4, inv_log_quant_transform, 
                                                        min = 0, max = q_999999))

  #now we can run logistic regression
    glm_1 <- glm(outcome ~ untransformed_imputed_biomarker_1 + confounder,
                data = my_data_iteration,
                family = "binomial")
  
    values_CLQI_1[imp] <- summary(glm_1)$coefficients[2]
    SE_CLQI_1[imp] <- summary(glm_1)$coefficients[2,2]
  
    #second one
    glm_2 <- glm(outcome ~ untransformed_imputed_biomarker_2 + confounder,
                data = my_data_iteration,
                family = "binomial")
  
    values_CLQI_2[imp] <- summary(glm_2)$coefficients[2]
    SE_CLQI_2[imp] <- summary(glm_2)$coefficients[2,2]
  
    #third one
    glm_3 <- glm(outcome ~ untransformed_imputed_biomarker_3 + confounder,
                data = my_data_iteration,
                family = "binomial")
  
    values_CLQI_3[imp] <- summary(glm_3)$coefficients[2]
    SE_CLQI_3[imp] <- summary(glm_3)$coefficients[2,2]
    
    #fourth one
    glm_4 <- glm(outcome ~ untransformed_imputed_biomarker_4 + confounder,
                data = my_data_iteration,
                family = "binomial")
  
    values_CLQI_4[imp] <- summary(glm_4)$coefficients[2]
    SE_CLQI_4[imp] <- summary(glm_4)$coefficients[2,2]
  } 
  
  CLQI_results <- data.frame(
    values_CLQI_1 = values_CLQI_1,
    SE_CLQI_1 = SE_CLQI_1,
    values_CLQI_2 = values_CLQI_2,
    SE_CLQI_2 = SE_CLQI_2,
    values_CLQI_3 = values_CLQI_3,
    SE_CLQI_3 = SE_CLQI_3,
    values_CLQI_4 = values_CLQI_4,
    SE_CLQI_4 = SE_CLQI_4
  )
  
  return(CLQI_results)
}
```

Super quick test case!

```{r}
testing_data <- data_generation(sample_size = 1000, missing_prop = 0.3)
b <- CLQI(testing_data, num_MI_iter = 10)

#check out the bias of this thing
mean(b$values_CLQI_1) - log(1.1)
mean(b$values_CLQI_2) - log(1.1)
mean(b$values_CLQI_3) - log(1.1)
mean(b$values_CLQI_4) - log(1.1)
```

# Sensitivity Analysis Time!

```{r}
#this is to make reading the code much easier
set.seed(500)
my_sample <- 1000 #sample size for each dataset
num_sim <- 1000 #number of simulations
MI_iter <- 10
prop_data_missing <- 0.3 #proportion of data missing

#here are some vectors we have to define... this is still messy since it's not in a full function

estimate_values_CLQI_1 <- c()
SE_values_CLQI_1 <- c()
coverage_CLQI_1 <- c()
power_CLQI_1 <- c()

estimate_values_CLQI_2 <- c()
SE_values_CLQI_2 <- c()
coverage_CLQI_2 <- c()
power_CLQI_2 <- c()

estimate_values_CLQI_3 <- c()
SE_values_CLQI_3 <- c()
coverage_CLQI_3 <- c()
power_CLQI_3 <- c()

estimate_values_CLQI_4 <- c()
SE_values_CLQI_4 <- c()
coverage_CLQI_4 <- c()
power_CLQI_4 <- c()

#now for our loop
tictoc::tic() #check runtime for entire simulation
for(i in 1:num_sim) { #for each simulation
  data_for_imp <- data_generation(sample_size = my_sample, 
                                  missing_prop = prop_data_missing) #generate my data
  
  #get values for estimate and SE from CLQI
  CLQI_results <- CLQI(data_for_imp, num_MI_iter = MI_iter)
    
  #ESTIMATES
    estimate_values_CLQI_1[i] <- mean(CLQI_results$values_CLQI_1)
    estimate_values_CLQI_2[i] <- mean(CLQI_results$values_CLQI_2)
    estimate_values_CLQI_3[i] <- mean(CLQI_results$values_CLQI_3)
    estimate_values_CLQI_4[i] <- mean(CLQI_results$values_CLQI_4)
  
  #SE
    SE_values_CLQI_1[i] <- rubin_rule_SE(as.vector(CLQI_results$values_CLQI_1), 
                                         as.vector(CLQI_results$SE_CLQI_1))
    SE_values_CLQI_2[i] <- rubin_rule_SE(as.vector(CLQI_results$values_CLQI_2), 
                                         as.vector(CLQI_results$SE_CLQI_2))
    SE_values_CLQI_3[i] <- rubin_rule_SE(as.vector(CLQI_results$values_CLQI_3), 
                                         as.vector(CLQI_results$SE_CLQI_3))
    SE_values_CLQI_4[i] <- rubin_rule_SE(as.vector(CLQI_results$values_CLQI_4), 
                                         as.vector(CLQI_results$SE_CLQI_4))
    
  #generate t star value right now
  t_star <- qt(0.975, df = my_sample - 1)
    
  #Coverage
    coverage_CLQI_1[i] <- coverage(parameter = estimate_values_CLQI_1[i],
                                   SE = SE_values_CLQI_1[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
    
    coverage_CLQI_2[i] <- coverage(parameter = estimate_values_CLQI_2[i],
                                   SE = SE_values_CLQI_2[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
    
    coverage_CLQI_3[i] <- coverage(parameter = estimate_values_CLQI_3[i],
                                   SE = SE_values_CLQI_3[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
    
    coverage_CLQI_4[i] <- coverage(parameter = estimate_values_CLQI_4[i],
                                   SE = SE_values_CLQI_4[i],
                                   t_star = t_star,
                                   true_val = log(1.1))
      
  #Power
    power_CLQI_1[i] <- power(as.vector(CLQI_results$values_CLQI_1), 
                             as.vector(CLQI_results$SE_CLQI_1), MI_iter)
    power_CLQI_2[i] <- power(as.vector(CLQI_results$values_CLQI_2), 
                             as.vector(CLQI_results$SE_CLQI_2), MI_iter)
    power_CLQI_3[i] <- power(as.vector(CLQI_results$values_CLQI_3), 
                             as.vector(CLQI_results$SE_CLQI_3), MI_iter)
    power_CLQI_4[i] <- power(as.vector(CLQI_results$values_CLQI_4), 
                             as.vector(CLQI_results$SE_CLQI_4), MI_iter)

  #we will be repeating this 1000 times
}
tictoc::toc()

#create bias rows
bias_values_CLQI_1 <- estimate_values_CLQI_1 - log(1.1)
bias_values_CLQI_2 <- estimate_values_CLQI_2 - log(1.1)
bias_values_CLQI_3 <- estimate_values_CLQI_3 - log(1.1)
bias_values_CLQI_4 <- estimate_values_CLQI_4 - log(1.1)


#and at the end, combine all these vectors into a single dataframe
my_simulation_results <- data.frame(
  estimate_values_CLQI_1 = estimate_values_CLQI_1,
  bias_values_CLQI_1 = bias_values_CLQI_1,
  SE_values_CLQI_1 = SE_values_CLQI_1,
  RMSE_values_CLQI_1 = sqrt(bias_values_CLQI_1^2 + SE_values_CLQI_1^2),
  coverage_CLQI_1 = coverage_CLQI_1,
  power_CLQI_1 = power_CLQI_1,
  
  estimate_values_CLQI_2 = estimate_values_CLQI_2,
  bias_values_CLQI_2 = bias_values_CLQI_2,
  SE_values_CLQI_2 = SE_values_CLQI_2,
  RMSE_values_CLQI_2 = sqrt(bias_values_CLQI_2^2 + SE_values_CLQI_2^2),
  coverage_CLQI_2 = coverage_CLQI_2,
  power_CLQI_2 = power_CLQI_2,
  
  estimate_values_CLQI_3 = estimate_values_CLQI_3,
  bias_values_CLQI_3 = bias_values_CLQI_3,
  SE_values_CLQI_3 = SE_values_CLQI_3,
  RMSE_values_CLQI_3 = sqrt(bias_values_CLQI_3^2 + SE_values_CLQI_3^2),
  coverage_CLQI_3 = coverage_CLQI_3,
  power_CLQI_3 = power_CLQI_3,
  
  estimate_values_CLQI_4 = estimate_values_CLQI_4,
  bias_values_CLQI_4 = bias_values_CLQI_4,
  SE_values_CLQI_4 = SE_values_CLQI_4,
  RMSE_values_CLQI_4 = sqrt(bias_values_CLQI_4^2 + SE_values_CLQI_4^2),
  coverage_CLQI_4 = coverage_CLQI_4,
  power_CLQI_4 = power_CLQI_4
)

my_simulation_results
saveRDS(my_simulation_results, file="./sensitivity_analysis_30_percent.rds")
```

```{r}
#quick bias checks
mean(my_simulation_results$estimate_values_CLQI) - log(1.1)
mean(my_simulation_results$estimate_values_PMM) - log(1.1)

#now for coverage
mean(my_simulation_results$coverage_CLQI)
mean(my_simulation_results$coverage_PMM)

#now for power
mean(my_simulation_results$power_CLQI)
mean(my_simulation_results$power_PMM)

#save this!
saveRDS(my_simulation_results, file="./simulations.rds")
```

Now a check!

```{r}
simulation_setting <- readRDS(file="./simulations.rds")

ggplot(data = simulation_setting, aes(x = estimate_values_CLQI)) +
  geom_density() +
  geom_vline(xintercept = log(1.1))

ggplot(data = simulation_setting, aes(x = estimate_values_PMM)) +
  geom_density() +
  geom_vline(xintercept = log(1.1))
```

#################################################################################
*I remember from STAT 495 that there was a cost vs power formula that we can use*

```{r}
# Plot histogram of your biomarker data
hist(created_data$biomarker, probability = TRUE, breaks = 100,
     col = "lightgray", border = "white",
     main = "Empirical Biomarker vs. Theoretical Mixture",
     xlab = "Biomarker")

# Generate a sequence of x-values covering the range of your data
x_vals <- seq(min(created_data$biomarker), 
              quantile(created_data$biomarker, 0.99), 
              length.out = 1000)

# Calculate theoretical mixture density
mixture_density <- 0.6 * dchisq(x_vals, df = 5) + 0.4 * dchisq(x_vals, df = 8)

# Overlay the theoretical density curve
lines(x_vals, mixture_density, col = "red", lwd = 2)

# Add a legend
legend("topright", legend = "Theoretical Mixture: 0.6 * χ²(5) + 0.4 * χ²(8)",
       col = "red", lwd = 2, bty = "n")
```

